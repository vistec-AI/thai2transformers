{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:PyTorch version 1.5.0a0+8f84ded available.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from transformers import (\n",
    "    CamembertTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForMaskedLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "#thai2transformers\n",
    "\n",
    "import os, sys\n",
    "sys.path.append('/workspace/thai2transformers/')\n",
    "\n",
    "from thai2transformers.datasets import MLMDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initialize tokenizer\n",
    "\n",
    "tokenizer = CamembertTokenizer(vocab_file='/workspace/thai2transformers/dataset/spm/th-wiki_only_20.7.2020_small_sentencepiece_for_camembert_16k/sentencepiece.bpe.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16005\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "#initialize models\n",
    "config = RobertaConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    type_vocab_size=1,\n",
    "    #roberta base as default\n",
    "    num_hidden_layers=12,\n",
    "    hidden_size=768, \n",
    "    intermediate_size=3072,\n",
    "    num_attention_head=12\n",
    "#     #roberta large\n",
    "#     num_hidden_layers=24,\n",
    "#     hidden_size=1024, \n",
    "#     intermediate_size=4096,\n",
    "#     num_attention_head=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RobertaForMaskedLM(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3db0e3c05c49e3a7b9826477c42dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96931688f1c5454c8e8187a688aabac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a278cba2f542e997f30b85aa9b3f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90004), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#datasets\n",
    "train_dataset = MLMDataset(tokenizer, '../dataset/split/th-wiki_only_20.7.2020_small/train', 512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1014f5d4b84fff89bdb59104bcfa33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35205dff8fe41d7bca473f1faa79d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641cb4d2caf948e5a635a0881c04c5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = MLMDataset(tokenizer, '../dataset/split/th-wiki_only_20.7.2020_small/val', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.training_args:PyTorch: setting up devices\n",
      "INFO:transformers.trainer:Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/lalital/huggingface\" target=\"_blank\">https://app.wandb.ai/lalital/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/lalital/huggingface/runs/3f6rf1gk\" target=\"_blank\">https://app.wandb.ai/lalital/huggingface/runs/3f6rf1gk</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wandb.run_manager:file/dir created: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-metadata.json\n",
      "INFO:wandb.run_manager:system metrics and metadata threads started\n",
      "INFO:wandb.run_manager:checking resume status, waiting at most 10 seconds\n",
      "INFO:wandb.run_manager:resuming run from id: UnVuOnYxOjNmNnJmMWdrOmh1Z2dpbmdmYWNlOmxhbGl0YWw=\n",
      "INFO:wandb.run_manager:upserting run before process can begin, waiting at most 10 seconds\n",
      "INFO:wandb.run_manager:saving pip packages\n",
      "INFO:wandb.run_manager:initializing streaming files api\n",
      "INFO:wandb.run_manager:unblocking file change observer, beginning sync with W&B servers\n",
      "INFO:wandb.run_manager:shutting down system stats and metadata service\n",
      "INFO:wandb.run_manager:file/dir modified: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/config.yaml\n",
      "INFO:wandb.run_manager:file/dir created: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-summary.json\n",
      "INFO:wandb.run_manager:file/dir created: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-events.jsonl\n",
      "INFO:wandb.run_manager:file/dir created: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-history.jsonl\n",
      "INFO:wandb.run_manager:file/dir created: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/requirements.txt\n",
      "INFO:wandb.run_manager:file/dir modified: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-metadata.json\n",
      "INFO:wandb.run_manager:file/dir modified: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-metadata.json\n",
      "INFO:wandb.run_manager:file/dir modified: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-events.jsonl\n",
      "INFO:wandb.run_manager:stopping streaming files and file change observer\n",
      "INFO:wandb.run_manager:file/dir modified: /workspace/thai2transformers/notebooks/wandb/run-20200721_062303-3f6rf1gk/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
    "\n",
    "#training args\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=4e-6,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    adam_epsilon=1e-6,\n",
    "    max_grad_norm=1.0,\n",
    "    #checkpoint\n",
    "    output_dir='./test_ckp/',\n",
    "    \n",
    "    save_total_limit=1,\n",
    "    save_steps=10,\n",
    "    #logs\n",
    "\n",
    "\n",
    "    #eval\n",
    "    evaluate_during_training=True,\n",
    "    eval_steps=10,\n",
    "    #others\n",
    "    seed=123,\n",
    "    fp16=False,\n",
    "\n",
    "    dataloader_drop_last=True\n",
    ")\n",
    "\n",
    "#initiate trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    "    \n",
    ")\n",
    "\n",
    "#train\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7fc12842bf60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:***** Running Evaluation *****\n",
      "INFO:transformers.trainer:  Num examples = 9999\n",
      "INFO:transformers.trainer:  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3feb8a1a346b41888e42929810bdb107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation', max=156, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# #save\n",
    "# trainer.save_model('test_lm')\n",
    "\n",
    "#evaluate\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
