{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Classification Finetuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "#misc\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import argparse\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "#torch \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#huggingface; only works with tokenizers==0.7.0 on mac now\n",
    "from transformers import (\n",
    "    AdamW, \n",
    "    get_linear_schedule_with_warmup, \n",
    "    AutoTokenizer, \n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoConfig,\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "\n",
    "#thai2transformers\n",
    "from thai2transformers.datasets import TokenClassificationDataset\n",
    "from thai2transformers.finetuners import TokenClassificationFinetuner\n",
    "from thai2transformers.metrics import classification_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download files\n",
    "import os\n",
    "if not os.path.exists('../data/wisesight-1000-samples-tokenised.label'):\n",
    "    !wget https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/master/word-tokenization/wisesight-1000-samples-tokenised.label\n",
    "    !mv wisesight-1000-samples-tokenised.label ../data/wisesight-1000-samples-tokenised.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af10c9f2eb4404f818f66c8526055f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'xlm-roberta-base',\n",
    ")\n",
    "train_dataset = TokenClassificationDataset(tokenizer,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wisesight-1000-samples-tokenised.label','r') as f:\n",
    "    x = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'eu', 'cer', 'in', 'ส', '_', 'ส', '_', 'ดี', 'q', '10', '</s>']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(i) for i in tokenizer('eucerin     ส_ส_ดี q10')['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'eu', 'cer', 'in', '_', 'สว', 'ัส', 'ดี', 'ครับ', '</s>']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thai2transformers.preprocess import process_transformers\n",
    "[tokenizer.decode(i) for i in tokenizer(process_transformers('eucerin สวัสดีครับ'))['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eu',\n",
       " 'cer',\n",
       " 'in',\n",
       " '|',\n",
       " '',\n",
       " '|',\n",
       " 'pro',\n",
       " '|',\n",
       " '',\n",
       " '|',\n",
       " 'ac',\n",
       " 'ne',\n",
       " '|',\n",
       " '',\n",
       " '|',\n",
       " 'ค่ะ',\n",
       " '|',\n",
       " '',\n",
       " '|',\n",
       " 'ใช้',\n",
       " '|',\n",
       " 'แล้ว',\n",
       " '|',\n",
       " 'สิว',\n",
       " '|',\n",
       " 'ขึ้น',\n",
       " '|',\n",
       " 'เพิ่ม',\n",
       " '|',\n",
       " 'ทุกวัน',\n",
       " '|',\n",
       " '',\n",
       " '|',\n",
       " 'มา',\n",
       " '|',\n",
       " 'ดู',\n",
       " '|',\n",
       " 'กัน',\n",
       " '|',\n",
       " 'นะ',\n",
       " '|',\n",
       " 'คะ',\n",
       " '|',\n",
       " '',\n",
       " '|',\n",
       " 'ว่า',\n",
       " '|',\n",
       " 'จัด',\n",
       " '|',\n",
       " 'การ',\n",
       " '|',\n",
       " 'ปัญหา',\n",
       " '|',\n",
       " 'สิว',\n",
       " '|',\n",
       " 'ใน',\n",
       " '|',\n",
       " '7',\n",
       " '|',\n",
       " 'วัน',\n",
       " '|',\n",
       " 'ได้',\n",
       " '|',\n",
       " 'รึ',\n",
       " '|',\n",
       " 'มั',\n",
       " '่',\n",
       " 'ย',\n",
       " 'ย',\n",
       " 'ยยย',\n",
       " 'ยยย',\n",
       " '|',\n",
       " '',\n",
       " '|',\n",
       " 'ล่า',\n",
       " '|',\n",
       " 'สุด',\n",
       " '|',\n",
       " 'ไป',\n",
       " '|',\n",
       " 'ล้าง',\n",
       " '|',\n",
       " 'หน',\n",
       " '้',\n",
       " '...']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "recon_txt = tokenizer.decode(tokenizer(x[i], add_special_tokens=False)['input_ids'])\n",
    "[tokenizer.decode(i) for i in tokenizer(recon_txt, add_special_tokens=False)['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eucerin| |pro| |acne| |ค่ะ| |ใช้|แล้ว|สิว|ขึ้น|เพิ่ม|ทุกวัน| |มา|ดู|กัน|นะ|คะ| |ว่า|จัด|การ|ปัญหา|สิว|ใน|7|วัน|ได้|รึ|มั่ยยยยยยยย| |ล่า|สุด|ไป|ล้าง|หน้...'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(fname):\n",
    "    with open(f'{fname}.src','r') as f:\n",
    "        src = [i.strip().replace('||','| |') for i in f.readlines()]\n",
    "    with open(f'{fname}.trg','r') as f:\n",
    "        trg = [i.strip() for i in f.readlines()]\n",
    "    lab = []\n",
    "    for l in trg:\n",
    "        lab.append('|'.join([str(tags_dict[i]) for i in l.split('|')]))\n",
    "    df = pd.DataFrame({'src':src,'label':lab,'trg':trg})\n",
    "    df['nb_src'] = df.src.map(lambda x: len(x.split('|')))\n",
    "    df['nb_label'] = df.label.map(lambda x: len(x.split('|')))\n",
    "    assert (df.nb_src==df.nb_label).sum() == df.shape[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1077, 5), (359, 5), (360, 5), 516, 521, 517)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_df('data/ner_newmm/train')\n",
    "valid_df = get_df('data/ner_newmm/valid')\n",
    "test_df = get_df('data/ner_newmm/test')\n",
    "train_df.shape, valid_df.shape, test_df.shape, train_df.nb_src.max(), valid_df.nb_src.max(), test_df.nb_src.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_df(df,n=40):\n",
    "    df['src'] = df.src.map(lambda x: '|'.join(x.split('|')[:n]))\n",
    "    df['label'] = df.label.map(lambda x: '|'.join(x.split('|')[:n]))\n",
    "    return df\n",
    "train_df = trunc_df(train_df)\n",
    "valid_df = trunc_df(valid_df)\n",
    "test_df = trunc_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save\n",
    "# !rm -r data/train_ner; rm -r data/valid_ner; rm -r data/test_ner;\n",
    "# !mkdir data/train_ner; mkdir data/valid_ner; mkdir data/test_ner; \n",
    "# train_df.iloc[:,:2].to_csv('data/train_ner/train.csv',index=False)\n",
    "# valid_df.iloc[:,:2].to_csv('data/valid_ner/valid.csv',index=False)\n",
    "# test_df.iloc[:,:2].to_csv('data/test_ner/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'xlm-roberta-base',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4708935c0124b248b52ce1a34f4f721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c75c7d38b54481888199cc312154478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "◎| |การเมือง|เรื่อง|ชนชั้น| |​| |เลว|หมด|คนโง่|เข้า|ประณต| |​​​| |กราบไหว้|สูงส่ง|ช่าง|งาม|งด| |​​​| |พิ|โธ่| |พิ|ถัง|ลา|งั่ง|ถูก|หลอก|ใช้| |​​​| |ไป่|รู้|  1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1\n",
      "เป็น|​| |Hotel| |Buffet| |ราคา|กลางๆ|​|หัว|ละ|​| |198| |232| |HKD| |Nett| |ดังนั้น|อาหาร|ให้|เลือก|มี|น้อย|มาก|​| |ดิ่ม|ซำ|มี|แค่|2|อย่าง| |ขนมจีบ|เนื้อ 1|1|1|1|1|1|1|1|1|1|1|1|1|1|18|12|12|12|17|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|13|13|1|1|1\n",
      "วันนี้|พา|มา|ร้าน|ชิล|ๆ| |ชิวๆ|​| |กับ|โรตี|และ|นม|ต่างๆ| |วันนี้|ได้|สั่ง| |โอ|ดิบ|นมสด| |อพอลโล|ชาเขียว| |และ|ก็|ทิชชู|โอวัน|ติ|ล|รสชาติ|จะ|ไล่|ตามลำดับ|เนอะ| |โอ 1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a190d96df6084e38ab253a061c101b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1287a2b9b424fdcb38446ed0d50939a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edc711dfebd473e8fdd4d5d5c200f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a1edcca84d413e8b3e3fa52ae2e975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 10.1 s, sys: 184 ms, total: 10.2 s\n",
      "Wall time: 10 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1074, 359, 360)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = TokenClassificationDataset(tokenizer,'data/train_ner')\n",
    "valid_dataset = TokenClassificationDataset(tokenizer,'data/valid_ner')\n",
    "test_dataset = TokenClassificationDataset(tokenizer,'data/test_ner')\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'label_pad_token': '0',\n",
    "             'label_first_subword': False,\n",
    "             'num_labels':42,\n",
    "             'num_hidden':768,\n",
    "             'train_dir': 'data/train_ner',\n",
    "             'valid_dir': 'data/valid_ner',\n",
    "             'test_dir': 'data/test_ner',\n",
    "             'output_dir': './results',\n",
    "             'model_name_or_path':'xlm-roberta-base',\n",
    "             'max_length':128,\n",
    "             'drop_p': 0.1,\n",
    "             'learning_rate': 5e-5,\n",
    "             'weight_decay': 0.01,\n",
    "             'adam_epsilon': 1e-8,\n",
    "             'warmup_steps': 100,\n",
    "             'per_device_train_batch_size':32,\n",
    "             'per_device_eval_batch_size':64,\n",
    "             'num_train_epochs': 2,\n",
    "             'gradient_accumulation_steps':1,\n",
    "             'max_grad_norm': 1.0,\n",
    "             'n_gpu': torch.cuda.device_count(),\n",
    "             'fp_16': False,\n",
    "             'opt_level': 'O1',\n",
    "             'seed': 1412,\n",
    "             'save_total_limit': 1,\n",
    "             'early_stopping': True,\n",
    "             'patience': 3\n",
    "            }\n",
    "\n",
    "args = argparse.Namespace(**args_dict)\n",
    "model = TokenClassificationFinetuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(train_dataset, batch_size=7)\n",
    "batch = next(iter(dl))\n",
    "label = batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 128)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(\n",
    "    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n",
    ")\n",
    "pred_labs = preds.argmax(2).numpy()\n",
    "pred_labs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred_labs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  pred_labs\n",
       "0      30         25\n",
       "1      25         18\n",
       "2      25         23\n",
       "3      29         37\n",
       "4      30         37\n",
       "..    ...        ...\n",
       "28      1         18\n",
       "29      1          2\n",
       "30      1         37\n",
       "31      1         29\n",
       "32      1         23\n",
       "\n",
       "[241 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "dfs = []\n",
    "for i in range(batch['input_ids'].shape[0]):\n",
    "    df = pd.DataFrame({'word_ids':batch['word_ids'][i].numpy(),'label':batch['label'][i].numpy(),'pred_labs':pred_labs[i]})\n",
    "    df = df[df.label!=0].groupby('word_ids').max().reset_index(drop=True)\n",
    "    dfs.append(df)\n",
    "df_batch = pd.concat(dfs)\n",
    "df_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.004149377593360996,\n",
       " 'f1_micro': 0.004149377593360996,\n",
       " 'precision_micro': 0.004149377593360996,\n",
       " 'recall_micro': 0.004149377593360996,\n",
       " 'f1_macro': 0.0024691358024691358,\n",
       " 'precision_macro': 0.0015873015873015873,\n",
       " 'recall_macro': 0.005555555555555555,\n",
       " 'nb_samples': 241}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = argparse.Namespace(\n",
    "    label_ids=df_batch.label, predictions=df_batch.pred_labs\n",
    ")\n",
    "classification_metrics(pred,pred_labs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['word_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'label_pad_token': '0',\n",
    "             'label_first_subword': False,\n",
    "             'num_labels':42,\n",
    "             'num_hidden':768,\n",
    "             'train_dir': 'data/train_ner',\n",
    "             'valid_dir': 'data/valid_ner',\n",
    "             'test_dir': 'data/test_ner',\n",
    "             'output_dir': './results',\n",
    "             'model_name_or_path':'xlm-roberta-base',\n",
    "             'max_length':128,\n",
    "             'drop_p': 0.1,\n",
    "             'learning_rate': 5e-5,\n",
    "             'weight_decay': 0.01,\n",
    "             'adam_epsilon': 1e-8,\n",
    "             'warmup_steps': 100,\n",
    "             'per_device_train_batch_size':32,\n",
    "             'per_device_eval_batch_size':64,\n",
    "             'num_train_epochs': 2,\n",
    "             'gradient_accumulation_steps':1,\n",
    "             'max_grad_norm': 1.0,\n",
    "             'n_gpu': torch.cuda.device_count(),\n",
    "             'fp_16': False,\n",
    "             'opt_level': 'O1',\n",
    "             'seed': 1412,\n",
    "             'save_total_limit': 1,\n",
    "             'early_stopping': True,\n",
    "             'patience': 3\n",
    "            }\n",
    "\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=args.output_dir,\n",
    "    save_top_k=args.save_total_limit,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=args.patience,\n",
    "   verbose=False,\n",
    "   mode='min'\n",
    ")\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    precision=16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback = checkpoint_callback,\n",
    "    early_stop_callback=early_stop_callback if args.early_stopping else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "model = TokenClassificationFinetuner(args)\n",
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | XLMRobertaModel  | 278 M \n",
      "1 | head    | Sequential       | 622 K \n",
      "2 | loss_fn | CrossEntropyLoss | 0     \n",
      "INFO:lightning:\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | XLMRobertaModel  | 278 M \n",
      "1 | head    | Sequential       | 622 K \n",
      "2 | loss_fn | CrossEntropyLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e7db8006db4a568889d94f60e83a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5ea939d5464d439093488ef672d207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c5c9fb6b1a45e1a8fe2ecbf5a80c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36da25df3a634b93b59f98a26215eeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "◎| |การเมือง|เรื่อง|ชนชั้น| |​| |เลว|หมด|คนโง่|เข้า|ประณต| |​​​| |กราบไหว้|สูงส่ง|ช่าง|งาม|งด| |​​​| |พิ|โธ่| |พิ|ถัง|ลา|งั่ง|ถูก|หลอก|ใช้| |​​​| |ไป่|รู้|  1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1\n",
      "เป็น|​| |Hotel| |Buffet| |ราคา|กลางๆ|​|หัว|ละ|​| |198| |232| |HKD| |Nett| |ดังนั้น|อาหาร|ให้|เลือก|มี|น้อย|มาก|​| |ดิ่ม|ซำ|มี|แค่|2|อย่าง| |ขนมจีบ|เนื้อ 1|1|1|1|1|1|1|1|1|1|1|1|1|1|18|12|12|12|17|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|13|13|1|1|1\n",
      "วันนี้|พา|มา|ร้าน|ชิล|ๆ| |ชิวๆ|​| |กับ|โรตี|และ|นม|ต่างๆ| |วันนี้|ได้|สั่ง| |โอ|ดิบ|นมสด| |อพอลโล|ชาเขียว| |และ|ก็|ทิชชู|โอวัน|ติ|ล|รสชาติ|จะ|ไล่|ตามลำดับ|เนอะ| |โอ 1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1|1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad14f060fb9430cbaa1bd40175be9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38badd9b149142aa949532de6a551946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3457821af714444bb6f1ab69e7bf08ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00000: val_loss reached 2.12986 (best 2.12986), saving model to /home/cstorm125/thai2transformers/_ckpt_epoch_0.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00000: val_loss reached 2.12986 (best 2.12986), saving model to /home/cstorm125/thai2transformers/_ckpt_epoch_0.ckpt as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss reached 1.37551 (best 1.37551), saving model to /home/cstorm125/thai2transformers/_ckpt_epoch_1_v2.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00001: val_loss reached 1.37551 (best 1.37551), saving model to /home/cstorm125/thai2transformers/_ckpt_epoch_1_v2.ckpt as top 1\n",
      "Saving latest checkpoint..\n",
      "INFO:lightning:Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -r lightning_logs; rm -r output; mkdir output\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b15435f38b41bb9dea333c750b02cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e820fa730b94e91992214aa10e1c77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdeeb23e8b8e4f578a68f17a2108c256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_acc': 0.72392429771705,\n",
      " 'avg_test_f1_macro': 0.05039030268977899,\n",
      " 'avg_test_f1_micro': 0.72392429771705,\n",
      " 'avg_test_precision_macro': 2.0562163293594474e-05,\n",
      " 'avg_test_precision_micro': 0.72392429771705,\n",
      " 'avg_test_recall_macro': 0.07322287732988887,\n",
      " 'avg_test_recall_micro': 0.72392429771705,\n",
      " 'test_loss': 1.4044627986293814,\n",
      " 'total_samples': 11783}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.4044627986293814,\n",
       "  'avg_test_acc': 0.72392429771705,\n",
       "  'avg_test_f1_micro': 0.72392429771705,\n",
       "  'avg_test_precision_micro': 0.72392429771705,\n",
       "  'avg_test_recall_micro': 0.72392429771705,\n",
       "  'avg_test_f1_macro': 0.05039030268977899,\n",
       "  'avg_test_precision_macro': 2.0562163293594474e-05,\n",
       "  'avg_test_recall_macro': 0.07322287732988887,\n",
       "  'total_samples': 11783}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
